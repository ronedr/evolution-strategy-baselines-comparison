{
 "cells": [
  {
   "cell_type": "code",
   "id": "9bd6649e693d131d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T15:25:11.815245Z",
     "start_time": "2025-08-08T15:25:11.781739Z"
    }
   },
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/mnt/new_home/ronedr/evolution-strategy-baselines-comparison')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T15:25:28.381223Z",
     "start_time": "2025-08-08T15:25:11.820460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import jax\n",
    "import os\n",
    "from utils.problem_utils import get_problem_name\n",
    "from evosax.algorithms import algorithms\n",
    "from evosax.problems import CNN, TorchVisionProblem as Problem, identity_output_fn\n",
    "from tqdm import tqdm\n",
    "from experiment.run_experiments import run_experiment_permutations"
   ],
   "id": "62050126-03a2-4c1d-9d56-5fff032637d9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T15:25:28.405423Z",
     "start_time": "2025-08-08T15:25:28.382450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_generations = 100\n",
    "population_size = 128\n",
    "seeds = list(range(0, 5))\n",
    "result_dir = \"../experiment_results\"\n",
    "problems_torch_vision = [\"MNIST\", \"FashionMNIST\", \"CIFAR10\", \"SVHN\"]"
   ],
   "id": "2e3670c52eb2df19",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-07-20T16:08:27.871427Z"
    }
   },
   "outputs": [],
   "source": [
    "es_dict = {\n",
    "    \"SimpleES\": {},\n",
    "    \"LES\": {},\n",
    "    \"DES\": {},\n",
    "    \"EvoTF_ES\": {},\n",
    "    \"PGPE\": {},\n",
    "    \"Open_ES\": {},\n",
    "    \"SNES\": {},\n",
    "    \"Sep_CMA_ES\": {},\n",
    "    \"CMA_ES\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c361565a98d1a023",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Problems ..:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded: MNIST\n",
      "../experiment_results/TorchVisionProblem/MNIST/LearnedES.json\n",
      "Path exists\n",
      "../experiment_results/TorchVisionProblem/MNIST/SimpleES.json\n",
      "Path exists\n",
      "../experiment_results/TorchVisionProblem/MNIST/PGPE.json\n",
      "Path exists\n",
      "../experiment_results/TorchVisionProblem/MNIST/Open_ES.json\n",
      "Path exists\n",
      "../experiment_results/TorchVisionProblem/MNIST/SNES.json\n",
      "Path exists\n",
      "../experiment_results/TorchVisionProblem/MNIST/Sep_CMA_ES.json\n",
      "Path exists\n",
      "../experiment_results/TorchVisionProblem/MNIST/CMA_ES.json\n",
      "Path does not exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running ES algorithms:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A2025-07-31 00:47:43.110368: W external/xla/xla/hlo/transforms/simplifiers/hlo_rematerialization.cc:3021] Can't reduce memory use below -100.75GiB (-108176383735 bytes) by rematerialization; only reduced to 123.75GiB (132870640664 bytes), down from 123.75GiB (132870640664 bytes) originally\n",
      "2025-07-31 00:47:53.160517: W external/xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 61.87GiB (rounded to 66434031616)requested by op \n",
      "2025-07-31 00:47:53.160773: W external/xla/xla/tsl/framework/bfc_allocator.cc:512] **__________________________________________________________________________________________________\n",
      "E0731 00:47:53.160825 3981813 pjrt_stream_executor_client.cc:3026] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 66434031504 bytes. [tf-allocator-allocation-error='']\n",
      "Running ES algorithms:   0%|          | 0/1 [00:11<?, ?it/s]\n",
      "Loading Problems ..:  25%|██▌       | 1/4 [00:30<01:32, 30.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load: MNIST RESOURCE_EXHAUSTED: Out of memory while trying to allocate 66434031504 bytes.\n",
      "Successfully loaded: FashionMNIST\n",
      "../experiment_results/TorchVisionProblem/FashionMNIST/LearnedES.json\n",
      "Path exists\n",
      "../experiment_results/TorchVisionProblem/FashionMNIST/SimpleES.json\n",
      "Path exists\n",
      "../experiment_results/TorchVisionProblem/FashionMNIST/PGPE.json\n",
      "Path exists\n",
      "../experiment_results/TorchVisionProblem/FashionMNIST/Open_ES.json\n",
      "Path exists\n",
      "../experiment_results/TorchVisionProblem/FashionMNIST/SNES.json\n",
      "Path exists\n",
      "../experiment_results/TorchVisionProblem/FashionMNIST/Sep_CMA_ES.json\n",
      "Path exists\n",
      "../experiment_results/TorchVisionProblem/FashionMNIST/CMA_ES.json\n",
      "Path does not exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running ES algorithms:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A2025-07-31 00:48:07.314604: W external/xla/xla/hlo/transforms/simplifiers/hlo_rematerialization.cc:3021] Can't reduce memory use below -100.75GiB (-108176383735 bytes) by rematerialization; only reduced to 123.75GiB (132870640664 bytes), down from 123.75GiB (132870640664 bytes) originally\n",
      "2025-07-31 00:48:17.366952: W external/xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 61.87GiB (rounded to 66434031616)requested by op \n",
      "2025-07-31 00:48:17.367063: W external/xla/xla/tsl/framework/bfc_allocator.cc:512] ****________________________________________________________________________________________________\n",
      "E0731 00:48:17.367106 3981813 pjrt_stream_executor_client.cc:3026] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 66434031504 bytes. [tf-allocator-allocation-error='']\n",
      "Running ES algorithms:   0%|          | 0/1 [00:10<?, ?it/s]\n",
      "Loading Problems ..:  50%|█████     | 2/4 [00:54<00:53, 26.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load: FashionMNIST RESOURCE_EXHAUSTED: Out of memory while trying to allocate 66434031504 bytes.\n",
      "Successfully loaded: CIFAR10\n",
      "../experiment_results/TorchVisionProblem/CIFAR10/LearnedES.json\n",
      "Path does not exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running ES algorithms:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A2025-07-31 00:48:43.441080: W external/xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-07-31 00:48:43.618876: W external/xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 33.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-07-31 00:48:43.992528: W external/xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "Running ES algorithms:   0%|          | 0/1 [00:10<?, ?it/s]\n",
      "Loading Problems ..:  75%|███████▌  | 3/4 [01:21<00:26, 26.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load: CIFAR10 UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv.3 = (f32[1024,2048,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[1024,1024,32,32]{3,2,1,0} %bitcast.6894, f32[2048,8,5,5]{3,2,1,0} %bitcast.6901), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, feature_group_count=128, custom_call_target=\"__cudnn$convForward\", metadata={op_name=\"jit(eval)/jit(main)/vmap(CNN)/Conv_1/conv_general_dilated\" source_file=\"/home/ronedr/.local/lib/python3.11/site-packages/flax/linen/linear.py\" source_line=694}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 8606711808 bytes. [tf-allocator-allocation-error='']\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "Successfully loaded: SVHN\n",
      "../experiment_results/TorchVisionProblem/SVHN/LearnedES.json\n",
      "Path does not exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running ES algorithms:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A2025-07-31 00:49:14.036157: W external/xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "Running ES algorithms:   0%|          | 0/1 [00:08<?, ?it/s]\n",
      "Loading Problems ..: 100%|██████████| 4/4 [01:51<00:00, 27.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load: SVHN UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv.3 = (f32[1024,2048,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[1024,1024,32,32]{3,2,1,0} %bitcast.6894, f32[2048,8,5,5]{3,2,1,0} %bitcast.6901), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, feature_group_count=128, custom_call_target=\"__cudnn$convForward\", metadata={op_name=\"jit(eval)/jit(main)/vmap(CNN)/Conv_1/conv_general_dilated\" source_file=\"/home/ronedr/.local/lib/python3.11/site-packages/flax/linen/linear.py\" source_line=694}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 8606711808 bytes. [tf-allocator-allocation-error='']\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for task_name in tqdm([\"MNIST\", \"FashionMNIST\", \"CIFAR10\", \"SVHN\"], desc=\"Loading Problems ..\"):\n",
    "    try:\n",
    "        problem = Problem(task_name=task_name,\n",
    "                          network=CNN(\n",
    "                              num_filters=[8, 16],\n",
    "                              kernel_sizes=[(5, 5), (5, 5)],\n",
    "                              strides=[(1, 1), (1, 1)],\n",
    "                              mlp_layer_sizes=[10],\n",
    "                              output_fn=identity_output_fn\n",
    "                          ),\n",
    "                          batch_size=1024)\n",
    "        print(\"Successfully loaded:\", task_name)\n",
    "        for es in es_dict:\n",
    "            for seed in seeds:\n",
    "                key = jax.random.key(seed)\n",
    "                run_experiment_permutations(problems=[problem],\n",
    "                                            es_dict={es: es_dict[es]},\n",
    "                                            num_generations=num_generations,\n",
    "                                            population_size=population_size,\n",
    "                                            seed=seed,\n",
    "                                            result_dir=result_dir, \n",
    "                                            run_again_if_exist=False)\n",
    "    except Exception as e:\n",
    "        print(\"Failed to load:\", task_name, e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e964e0ae-3af8-4eac-985e-92d56d3ddf76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jax_cpu_env)",
   "language": "python",
   "name": "jax_cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
