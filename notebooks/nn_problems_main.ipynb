{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bd6649e693d131d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T15:25:11.815245Z",
     "start_time": "2025-08-08T15:25:11.781739Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/mnt/new_home/ronedr/evolution-strategy-baselines-comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0652c0e4-1eec-424b-8d16-ca944e3dc78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_strict_conv_algorithm_picker=false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62050126-03a2-4c1d-9d56-5fff032637d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T15:25:28.381223Z",
     "start_time": "2025-08-08T15:25:11.820460Z"
    }
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "from utils.problem_utils import get_problem_name\n",
    "from evosax.algorithms import algorithms\n",
    "from evosax.problems import CNN, TorchVisionProblem as Problem, identity_output_fn\n",
    "from tqdm import tqdm\n",
    "from experiment.run_experiments import run_experiment_permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e3670c52eb2df19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T15:25:28.405423Z",
     "start_time": "2025-08-08T15:25:28.382450Z"
    }
   },
   "outputs": [],
   "source": [
    "num_generations = 100\n",
    "population_size = 64\n",
    "seeds = list(range(0, 5))\n",
    "result_dir = \"../experiment_results\"\n",
    "problems_torch_vision = [\"MNIST\", \"FashionMNIST\", \"CIFAR10\", \"SVHN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-07-20T16:08:27.871427Z"
    }
   },
   "outputs": [],
   "source": [
    "es_dict = {\n",
    "    \"SimpleES\": {},\n",
    "    \"LES\": {},\n",
    "    \"DES\": {},\n",
    "    \"EvoTF_ES\": {},\n",
    "    \"PGPE\": {},\n",
    "    \"Open_ES\": {},\n",
    "    \"SNES\": {},\n",
    "    \"Sep_CMA_ES\": {},\n",
    "    \"CMA_ES\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c361565a98d1a023",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Problems ..:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded: MNIST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running ES algorithms:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running the experiment ... [../experiment_results/TorchVisionProblem/MNIST/SimpleES/0.json]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 18:44:30.526171: W external/xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-08 18:44:30.705196: W external/xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.39GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-08 18:44:30.705273: W external/xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.65GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-08 18:44:30.705312: W external/xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.00GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-08 18:44:31.049580: W external/xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-08 18:44:31.049744: W external/xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:1095] Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv.3 = (f32[1024,1024,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[1024,512,28,28]{3,2,1,0} %bitcast.6932, f32[1024,8,5,5]{3,2,1,0} %bitcast.6936), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convForward\", metadata={op_name=\"jit(eval)/jit(main)/vmap(CNN)/Conv_1/conv_general_dilated\" source_file=\"/home/ronedr/.local/lib/python3.11/site-packages/flax/linen/linear.py\" source_line=694}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 3305111552 bytes. [tf-allocator-allocation-error='']\n",
      "\n",
      "As a result, convolution performance may be suboptimal.\n",
      "2025-08-08 18:44:33.378685: W external/xla/xla/hlo/transforms/simplifiers/hlo_rematerialization.cc:3021] Can't reduce memory use below 5.61GiB (6025341248 bytes) by rematerialization; only reduced to 6.12GiB (6576673308 bytes), down from 6.12GiB (6576673308 bytes) originally\n",
      "2025-08-08 18:44:45.047240: W external/xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.12GiB (rounded to 6577493504)requested by op \n",
      "2025-08-08 18:44:45.047507: W external/xla/xla/tsl/framework/bfc_allocator.cc:512] ******______________________________________________________________________________________________\n",
      "E0808 18:44:45.047530 2421943 pjrt_stream_executor_client.cc:3026] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 6577493416 bytes. [tf-allocator-allocation-error='']\n",
      "Running ES algorithms:   0%|          | 0/1 [00:22<?, ?it/s]\n",
      "Loading Problems ..:  25%|██▌       | 1/4 [00:49<02:29, 49.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load: MNIST RESOURCE_EXHAUSTED: Out of memory while trying to allocate 6577493416 bytes.\n",
      "Successfully loaded: FashionMNIST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running ES algorithms:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running the experiment ... [../experiment_results/TorchVisionProblem/FashionMNIST/SimpleES/0.json]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 18:45:05.337869: W external/xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.39GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-08 18:45:05.337921: W external/xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.65GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-08 18:45:05.337949: W external/xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.00GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-08 18:45:05.817099: W external/xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-08 18:45:05.817199: W external/xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:1095] Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv.3 = (f32[1024,1024,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[1024,512,28,28]{3,2,1,0} %bitcast.6932, f32[1024,8,5,5]{3,2,1,0} %bitcast.6936), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convForward\", metadata={op_name=\"jit(eval)/jit(main)/vmap(CNN)/Conv_1/conv_general_dilated\" source_file=\"/home/ronedr/.local/lib/python3.11/site-packages/flax/linen/linear.py\" source_line=694}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 3305111552 bytes. [tf-allocator-allocation-error='']\n",
      "\n",
      "As a result, convolution performance may be suboptimal.\n",
      "2025-08-08 18:45:06.234457: W external/xla/xla/hlo/transforms/simplifiers/hlo_rematerialization.cc:3021] Can't reduce memory use below 5.61GiB (6025341248 bytes) by rematerialization; only reduced to 6.12GiB (6576673308 bytes), down from 6.12GiB (6576673308 bytes) originally\n",
      "2025-08-08 18:45:17.881518: W external/xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.12GiB (rounded to 6577493504)requested by op \n",
      "2025-08-08 18:45:17.881745: W external/xla/xla/tsl/framework/bfc_allocator.cc:512] ******__****________________________________________________________________________________________\n",
      "E0808 18:45:17.881766 2421943 pjrt_stream_executor_client.cc:3026] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 6577493416 bytes. [tf-allocator-allocation-error='']\n",
      "Running ES algorithms:   0%|          | 0/1 [00:16<?, ?it/s]\n",
      "Loading Problems ..:  50%|█████     | 2/4 [01:22<01:19, 39.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load: FashionMNIST RESOURCE_EXHAUSTED: Out of memory while trying to allocate 6577493416 bytes.\n",
      "Successfully loaded: CIFAR10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running ES algorithms:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running the experiment ... [../experiment_results/TorchVisionProblem/CIFAR10/SimpleES/0.json]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 18:45:53.511734: W external/xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-08-08 18:45:53.512488: W external/xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:1095] Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv.3 = (f32[1024,1024,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[1024,512,32,32]{3,2,1,0} %bitcast.6932, f32[1024,8,5,5]{3,2,1,0} %bitcast.6936), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convForward\", metadata={op_name=\"jit(eval)/jit(main)/vmap(CNN)/Conv_1/conv_general_dilated\" source_file=\"/home/ronedr/.local/lib/python3.11/site-packages/flax/linen/linear.py\" source_line=694}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 4311744512 bytes. [tf-allocator-allocation-error='']\n",
      "\n",
      "As a result, convolution performance may be suboptimal.\n",
      "2025-08-08 18:45:56.498871: W external/xla/xla/hlo/transforms/simplifiers/hlo_rematerialization.cc:3021] Can't reduce memory use below 5.60GiB (6015905088 bytes) by rematerialization; only reduced to 8.00GiB (8589939228 bytes), down from 8.00GiB (8589939228 bytes) originally\n",
      "2025-08-08 18:46:13.850649: W external/xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.00GiB (rounded to 8590759424)requested by op \n",
      "2025-08-08 18:46:13.851168: W external/xla/xla/tsl/framework/bfc_allocator.cc:512] ******__******_______***********____________________________________________________________________\n",
      "E0808 18:46:13.851197 2421943 pjrt_stream_executor_client.cc:3026] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 8590759336 bytes. [tf-allocator-allocation-error='']\n",
      "Running ES algorithms:   0%|          | 0/1 [00:36<?, ?it/s]\n",
      "Loading Problems ..:  75%|███████▌  | 3/4 [02:18<00:47, 47.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load: CIFAR10 RESOURCE_EXHAUSTED: Out of memory while trying to allocate 8590759336 bytes.\n",
      "Successfully loaded: SVHN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running ES algorithms:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running the experiment ... [../experiment_results/TorchVisionProblem/SVHN/SimpleES/0.json]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 18:46:59.568683: W external/xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:1095] Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv.3 = (f32[1024,1024,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[1024,512,32,32]{3,2,1,0} %bitcast.6932, f32[1024,8,5,5]{3,2,1,0} %bitcast.6936), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convForward\", metadata={op_name=\"jit(eval)/jit(main)/vmap(CNN)/Conv_1/conv_general_dilated\" source_file=\"/home/ronedr/.local/lib/python3.11/site-packages/flax/linen/linear.py\" source_line=694}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 4311744512 bytes. [tf-allocator-allocation-error='']\n",
      "\n",
      "As a result, convolution performance may be suboptimal.\n",
      "2025-08-08 18:47:00.119479: W external/xla/xla/hlo/transforms/simplifiers/hlo_rematerialization.cc:3021] Can't reduce memory use below 5.60GiB (6015905088 bytes) by rematerialization; only reduced to 8.00GiB (8589939228 bytes), down from 8.00GiB (8589939228 bytes) originally\n",
      "2025-08-08 18:47:20.957717: W external/xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.00GiB (rounded to 8590759424)requested by op \n",
      "2025-08-08 18:47:20.958210: W external/xla/xla/tsl/framework/bfc_allocator.cc:512] ******__******_______****************________***************________________________________________\n",
      "E0808 18:47:20.958270 2421943 pjrt_stream_executor_client.cc:3026] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 8590759344 bytes. [tf-allocator-allocation-error='']\n",
      "Running ES algorithms:   0%|          | 0/1 [00:41<?, ?it/s]\n",
      "Loading Problems ..: 100%|██████████| 4/4 [03:25<00:00, 51.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load: SVHN RESOURCE_EXHAUSTED: Out of memory while trying to allocate 8590759344 bytes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for task_name in tqdm(problems_torch_vision, desc=\"Loading Problems ..\"):\n",
    "    try:\n",
    "        problem = Problem(task_name=task_name,\n",
    "                          network=CNN(\n",
    "                              num_filters=[8, 16],\n",
    "                              kernel_sizes=[(5, 5), (5, 5)],\n",
    "                              strides=[(1, 1), (1, 1)],\n",
    "                              mlp_layer_sizes=[10],\n",
    "                              output_fn=identity_output_fn\n",
    "                          ),\n",
    "                          batch_size=1024)\n",
    "        print(\"Successfully loaded:\", task_name)\n",
    "        for es in es_dict:\n",
    "            for seed in seeds:\n",
    "                key = jax.random.key(seed)\n",
    "                run_experiment_permutations(problems=[problem],\n",
    "                                            es_dict={es: es_dict[es]},\n",
    "                                            num_generations=num_generations,\n",
    "                                            population_size=population_size,\n",
    "                                            seed=seed,\n",
    "                                            result_dir=result_dir, \n",
    "                                            run_again_if_exist=False)\n",
    "    except Exception as e:\n",
    "        print(\"Failed to load:\", task_name, e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e964e0ae-3af8-4eac-985e-92d56d3ddf76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ronedr_es",
   "language": "python",
   "name": "ronedr_es_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
